模型分类
* 分类
* 回归
* 排序
---
四大基本要素
* 数据集
* 目标函数
  * 代价函数
  * 损失函数
  * 收益函数
  * 等等来指代，根据不同场景确定
* 模型
* 优化算法
---
以损失函数为例，总体损失函数为样本损失函数期望值J<sup>*</sup>
由于实际只有样本集概率密度函数 *p*(**x**,**y**)未知故J<sup>*</sup>无法计算，于是J诞生
* 经验损失函数（训练集上获取）
* 测试集损失（测试集上获取，可反映模型泛化能力）

---
模型分为
* 非参数模型（其表示穗具体应用而定，不易给一般表示）
* 参数模型
  * 一般形式为$\hat{y}$=*h*(**x**;**w**)
    * $\hat{y}$对**w**是否线性，决定系统优化的复杂度
    * $\hat{y}$对**x**是否线性，决定系统的表达能力
  * 参数模型基本分为：
    * 线性
    * 非线性
  * 过拟合和欠拟合
    * 过拟合在训练集上误差理想，但是测试集上误差大，泛化能力差
    * 欠拟合模型过于简单无法表示数据的复杂规律
      * 这种情况下选择复杂的模型，这时候就得克服过拟合的问题，其中一种方法就是正则化（Regulation）
  * 正则化：对目标函数增加一个约束项，以损失函数为例
    * 若目标函数为损失函数，*L<sub>new</sub>=L<sub>old</sub>+约束项*，约束项上一般施加一个权重因子λ，来平衡损失函数和约束项的影响强度
    * λ是一种超参数，超参数一般不能由训练过程得出，大多通过交叉验证确定。

---
优化算法
> 数据，目标函数，模型选定后，要通过优化算法确定模型

如对于参数模型，需用训练数据对描述模型的目标函数优化得到模型参数
* 若对一类机器学习问题直接使用已有的优化算法即可有效求解，则直接使用这些算法
* 若没有有效算法或算法效率低，则探索新算法或者改进现有算法

---
机器学习概念
* 输入空间
> 包含所研究对象特征向量的空间
> * 特征向量为10维向量，则为10维空间
> * 特征向量1000维向量，每个分量只能取0或1，输入空间为2<sup>1000</sup>集合

* 输出空间
> 以垃圾邮件分类为例，为{是垃圾邮寄，不是垃圾邮件}

* 假设空间
> 从输入到输出映射关系的函数空间，如$\hat{y}(x,w)=w_{0}+\sum_{k=1}^{K}w_{k}x_{k}$,该假设空间为吧=把K维向量映射为一维实数空间的所有线性函数集合，有无穷多成员


# 进度到1.4
